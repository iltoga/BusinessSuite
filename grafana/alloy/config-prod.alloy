// 1. Discover Docker containers - increased refresh interval to 60s to save CPU
discovery.docker "docker_loader" {
  host             = "unix:///var/run/docker.sock"
  refresh_interval = "15s"
}

// 2. Filter targets
discovery.relabel "bs_services" {
  targets = discovery.docker.docker_loader.targets

  rule {
    source_labels = ["__meta_docker_container_name"]
    regex         = "/?(bs-core|bs-worker|bs-frontend)"
    action        = "keep"
  }

  rule {
    source_labels = ["__meta_docker_container_name"]
    regex         = "/?(.*)"
    target_label  = "service"
  }
}

// 3. LOG PROCESSING PIPELINE (Filters noise here)
loki.process "filter_logs" {
  forward_to = [loki.write.grafana_cloud.receiver]

  // Drop Django "Invalid HTTP_HOST header" errors
  stage.drop {
    expression = ".*Invalid HTTP_HOST header.*"
  }

  // Drop general scanner noise (zgrab, Palo Alto, etc.) seen in your logs
  stage.drop {
    expression = "(?i).*(zgrab|Palo Alto Networks|Cortex-Xpanse|scanning).*"
  }
}

// 4. Scrape logs from Docker
loki.source.docker "bs_log_scraper" {
  host       = "unix:///var/run/docker.sock"
  targets    = discovery.relabel.bs_services.output
  // Forward to the filter instead of directly to cloud
  forward_to = [loki.process.filter_logs.receiver]
}

// 5. Scrape persisted host log files from the shared DATA_PATH logs volume
local.file_match "host_log_files" {
  path_targets = [
    { "__path__" = "/host_logs/django.log", "job" = "host_logs", "service" = "bs-core" },
    { "__path__" = "/host_logs/task_worker.log", "job" = "host_logs", "service" = "bs-worker" },
    { "__path__" = "/host_logs/frontend.log", "job" = "host_logs", "service" = "bs-frontend" },
  ]
}

loki.source.file "host_logs" {
  targets    = local.file_match.host_log_files.targets
  forward_to = [loki.process.filter_logs.receiver]
}

// 6. Send logs to Grafana Cloud
loki.write "grafana_cloud" {
  endpoint {
    url = sys.env("GRAFANA_CLOUD_LOKI_URL")

    basic_auth {
      username = sys.env("GRAFANA_CLOUD_LOKI_USER")
      password = sys.env("GRAFANA_CLOUD_LOKI_API_KEY")
    }

    batch_size = "512KiB"
    batch_wait = "5s"
  }
}

// 7. Trace export auth for Grafana Cloud OTLP/Tempo
otelcol.auth.basic "grafana_cloud_otlp" {
  username = sys.env("GRAFANA_CLOUD_OTLP_USER")
  password = sys.env("GRAFANA_CLOUD_OTLP_API_KEY")
}

// 8. Export traces to Grafana Cloud
otelcol.exporter.otlphttp "grafana_cloud_traces" {
  client {
    endpoint = sys.env("GRAFANA_CLOUD_OTLP_ENDPOINT")
    auth     = otelcol.auth.basic.grafana_cloud_otlp.handler
  }
}

// 9. Batch traces before export
otelcol.processor.batch "trace_batch" {
  output {
    traces = [otelcol.exporter.otlphttp.grafana_cloud_traces.input]
  }
}

// 10. Receive OTLP traces from backend, worker, and frontend clients
otelcol.receiver.otlp "app_traces" {
  grpc {
    endpoint = "0.0.0.0:4317"
  }

  http {
    endpoint = "0.0.0.0:4318"

    // Keep broad CORS for browser OTLP; restrict this list if you proxy OTLP through a single origin.
    cors {
      allowed_origins = ["*"]
      allowed_headers = ["*"]
      max_age         = 7200
    }
  }

  output {
    traces = [otelcol.processor.batch.trace_batch.input]
  }
}
