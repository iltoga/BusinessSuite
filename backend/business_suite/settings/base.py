"""
Django settings for business_suite project.

Generated by 'django-admin startproject' using Django 4.2.1.

For more information on this file, see
https://docs.djangoproject.com/en/4.2/topics/settings/

For the full list of settings and their values, see
https://docs.djangoproject.com/en/4.2/ref/settings/
"""

import json
import logging
import os
import socket
import sys
from datetime import timedelta
from importlib import import_module
from pathlib import Path

from business_suite.settings.cache_backends import build_prod_redis_caches
from dotenv import load_dotenv

# Load environment variables from .env file
load_dotenv()

# Build paths inside the project like this: BASE_DIR / 'subdir'.
BASE_DIR = Path(__file__).resolve().parent.parent

# Ensure logs directory exists at the project root (one level up from BASE_DIR)
# This ensures that Grafana Alloy can consistently scrape them from a single location.
ROOT_DIR = BASE_DIR.parent
LOG_DIR = os.path.join(ROOT_DIR, "logs")
if not os.path.exists(LOG_DIR):
    os.makedirs(LOG_DIR, exist_ok=True)
LOGS_DIR = LOG_DIR  # Alias for backward compatibility
# enable or disable client-side logging endpoint
CLIENT_LOGS_ENABLED = os.getenv("CLIENT_LOGS_ENABLED") == "True"

# Static and Media paths - defined early as they are used by other settings and services
# Allow overriding via env var so production can point MEDIA_ROOT to a host-mounted path
MEDIA_ROOT = os.getenv("MEDIA_ROOT", os.path.join(BASE_DIR, "files/media/"))
MEDIA_URL = os.getenv("MEDIA_URL", "/uploads/")
BACKUPS_ROOT = os.getenv("BACKUPS_ROOT", os.path.join(BASE_DIR, "backups"))
STATIC_ROOT = os.path.join(BASE_DIR, "staticfiles")
STATIC_SOURCE_ROOT = os.path.join(BASE_DIR, "static")

DOCUMENTS_FOLDER = "documents"
APPLICATION_DEFAULT_FILES_FOLDER = "application_default_files"
TMPFILES_FOLDER = "tmpfiles"

# Critical Document Template Settings - must be defined early to avoid circular import issues
DOCX_INVOICE_TEMPLATE_NAME = os.getenv("DOCX_INVOICE_TEMPLATE_NAME", "invoice_template_with_footer.docx")
DOCX_PARTIAL_INVOICE_TEMPLATE_NAME = os.getenv(
    "DOCX_PARTIAL_INVOICE_TEMPLATE_NAME", "partial_invoice_template_with_footer.docx"
)
DOCX_SURAT_PERMOHONAN_PERPANJANGAN_TEMPLATE_NAME = os.getenv(
    "DOCX_SURAT_PERMOHONAN_PERPANJANGAN_TEMPLATE_NAME", "surat_permohonan_perpanjangan.docx"
)

# Document Type Hooks Settings
# Path to the default sponsor passport file (relative to MEDIA_ROOT)
DEFAULT_SPONSOR_PASSPORT_FILE_PATH = os.getenv(
    "DEFAULT_SPONSOR_PASSPORT_FILE_PATH", "default_documents/default_sponsor_document.pdf"
)

# default language for generated documents
DEFAULT_DOCUMENT_LANGUAGE_CODE = os.getenv("DEFAULT_DOCUMENT_LANGUAGE_CODE", "id")

DEFAULT_CUSTOMER_EMAIL = os.getenv("DEFAULT_CUSTOMER_EMAIL", "sample_email@gmail.com")

CHECK_PASSPORT_MODEL = os.getenv("CHECK_PASSPORT_MODEL", "google/gemini-2.5-flash")
CHECK_PASSPORT_AI_MIN_CONFIDENCE_FOR_UPLOAD = float(os.getenv("CHECK_PASSPORT_AI_MIN_CONFIDENCE_FOR_UPLOAD", "0.75"))


# MOCK AUTH SETTINGS
def _parse_bool(value, default=False):
    if value is None:
        return default
    if isinstance(value, bool):
        return value
    # Strip common quote characters and whitespace
    s = str(value).strip().strip('"').strip("'").lower()
    return s in {"true", "1", "yes", "y", "on"}


def _parse_list(value, default=None):
    if value is None:
        return default if default is not None else []
    items = [item.strip() for item in str(value).split(",")]
    return [item for item in items if item]


def _resolved_db_host():
    host = (os.getenv("DB_HOST") or "").strip()
    if not host:
        return "localhost"

    # Inside Docker, localhost points to the current container.
    # If env still provides loopback, prefer the Compose service name.
    if os.path.exists("/.dockerenv") and host in {"localhost", "127.0.0.1", "::1"}:
        return "db"
    return host


def _resolved_redis_host():
    host = (os.getenv("REDIS_HOST") or "").strip()
    if host:
        return host

    # Host-run local development should connect via the published port.
    if not os.path.exists("/.dockerenv"):
        return "localhost"

    # Inside Docker, use the Redis container name configured in compose.
    return "bs-redis"


MOCK_AUTH_ENABLED = _parse_bool(os.getenv("MOCK_AUTH_ENABLED", "False"))
MOCK_AUTH_USERNAME = os.getenv("MOCK_AUTH_USERNAME", "mockuser")
MOCK_AUTH_EMAIL = os.getenv("MOCK_AUTH_EMAIL", "mock@example.com")
MOCK_AUTH_IS_SUPERUSER = _parse_bool(os.getenv("MOCK_AUTH_IS_SUPERUSER", "True"))
MOCK_AUTH_IS_STAFF = _parse_bool(os.getenv("MOCK_AUTH_IS_STAFF", "True"))
MOCK_AUTH_GROUPS = _parse_list(os.getenv("MOCK_AUTH_GROUPS", "admin"))
MOCK_AUTH_ROLES = _parse_list(os.getenv("MOCK_AUTH_ROLES", "admin"))

GLOBAL_SETTINGS = {
    "SITE_NAME": os.getenv("SITE_NAME", "Business Suite"),
    "SITE_DESCRIPTION": os.getenv(
        "SITE_DESCRIPTION",
        "Comprehensive ERP for service agencies: CRM, catalog, applications, invoicing, payments, document management.",
    ),
    "DOCUMENT_EXPIRATION_NOTIFICATION_DAYS": 180,
    "LOGO_FILENAME": os.getenv("LOGO_FILENAME", "logo_transparent.png"),
    "LOGO_INVERTED_FILENAME": os.getenv("LOGO_INVERTED_FILENAME", "logo_inverted_transparent.png"),
}

# Date format exposed to Angular frontend via /api/app-config/.
# Uses Angular DatePipe tokens (e.g. dd-MM-yyyy, yyyy-MM-dd, dd/MM/yyyy).
DATE_FORMAT_JS = os.getenv("DATE_FORMAT_JS", "dd-MM-yyyy")

# Legacy Django template views have been removed; always redirect to admin after login.
LOGIN_REDIRECT_URL = "/admin/"

# Invoice Import Settings
INVOICE_IMPORT_MAX_WORKERS = int(os.getenv("INVOICE_IMPORT_MAX_WORKERS", "3"))  # Max parallel imports

# Logging level configuration
DJANGO_LOG_LEVEL = os.getenv("DJANGO_LOG_LEVEL", os.getenv("LOG_LEVEL", "INFO"))
LOGGING_LEVEL = DJANGO_LOG_LEVEL


# Quick-start development settings - unsuitable for production
# See https://docs.djangoproject.com/en/4.2/howto/deployment/checklist/

# SECURITY WARNING: keep the secret key used in production secret!
SECRET_KEY = os.getenv("SECRET_KEY")
APP_DOMAIN = os.getenv("APP_DOMAIN")

# SECURITY WARNING: don't run with debug turned on in production!
DEBUG = os.getenv("DJANGO_DEBUG", "False") == "True"

ALLOWED_HOSTS = [
    "localhost",
    "127.0.0.1",
    "[::1]",
    os.getenv("APP_DOMAIN", ""),
]


# Application definition

INSTALLED_APPS = [
    "django.contrib.admin",
    "django.contrib.auth",
    "django.contrib.contenttypes",
    "django.contrib.sessions",
    "django.contrib.messages",
    "django.contrib.staticfiles",
    "django.contrib.postgres",
    "cacheops",  # Django-cacheops for automatic ORM query caching
    "core.apps.CoreConfig",
    "cache.apps.CacheConfig",  # Hybrid cache system with namespace versioning
    "landing",
    "customers",
    "products",
    "invoices.apps.InvoicesConfig",
    "payments",
    "customer_applications",
    "letters",
    "reports",
    "corsheaders",
    "rest_framework",
    "drf_spectacular",
    "rest_framework.authtoken",
    "nested_admin",
    "django.contrib.humanize",
    "debug_toolbar",
    "waffle",
    "dbbackup",
    "storages",
    "admin_tools",
    "django_cleanup.apps.CleanupConfig",
    "huey.contrib.djhuey",
]

MIDDLEWARE = [
    "debug_toolbar.middleware.DebugToolbarMiddleware",
    "django.middleware.security.SecurityMiddleware",
    # CORS middleware should be as high as possible so CORS headers are applied
    # to all responses (see django-cors-headers docs).
    "corsheaders.middleware.CorsMiddleware",
    "whitenoise.middleware.WhiteNoiseMiddleware",  # to serve static files
    "django.contrib.sessions.middleware.SessionMiddleware",
    "django.middleware.common.CommonMiddleware",
    "django.middleware.csrf.CsrfViewMiddleware",
    "django.contrib.auth.middleware.AuthenticationMiddleware",
    # Cache middleware must be after AuthenticationMiddleware to access request.user
    "cache.middleware.CacheMiddleware",
    # Waffle must be after AuthenticationMiddleware to access request.user
    "waffle.middleware.WaffleMiddleware",
    # Custom middlewares that might rely on Waffle flags or Auth
    "business_suite.middlewares.AuthLoginRequiredMiddleware",
    "django.contrib.messages.middleware.MessageMiddleware",
    "django.middleware.clickjacking.XFrameOptionsMiddleware",
    "core.middleware.performance_logger.PerformanceLoggingMiddleware",
]

ROOT_URLCONF = "business_suite.urls"

TEMPLATES = [
    {
        "BACKEND": "django.template.backends.django.DjangoTemplates",
        "DIRS": [
            os.path.join(BASE_DIR, "templates"),
            os.path.join(BASE_DIR, "business_suite", "templates"),
        ],
        "APP_DIRS": True,
        "OPTIONS": {
            "context_processors": [
                "django.template.context_processors.debug",
                "django.template.context_processors.request",
                "django.contrib.auth.context_processors.auth",
                "django.contrib.messages.context_processors.messages",
                "django.template.context_processors.request",
                "business_suite.context_processors.site_info",
            ],
        },
    },
]

WSGI_APPLICATION = "business_suite.wsgi.application"


# Database
# https://docs.djangoproject.com/en/4.2/ref/settings/#databases

# DATABASES = {
#     "default": {
#         "ENGINE": "django.db.backends.sqlite3",
#         "NAME": os.path.join(BASE_DIR, "files/db.sqlite3"),
#     }
# }
# Use an in-memory SQLite DB when running tests to avoid requiring Postgres.
# Do not infer testing from PYTEST_CURRENT_TEST alone, as leaked shell env can
# incorrectly force non-test processes (e.g. run_huey) into test mode.
_DJANGO_TESTING_ENV = os.getenv("DJANGO_TESTING")
if _DJANGO_TESTING_ENV is not None:
    TESTING = _parse_bool(_DJANGO_TESTING_ENV)
else:
    _is_pytest = any("pytest" in Path(arg).name for arg in sys.argv)
    _is_django_test_cmd = len(sys.argv) > 1 and sys.argv[1] == "test"
    TESTING = _is_pytest or _is_django_test_cmd

if TESTING:
    DATABASES = {
        "default": {
            "ENGINE": "django.db.backends.sqlite3",
            "NAME": ":memory:",
        }
    }
else:
    DATABASES = {
        "default": {
            "ENGINE": "django.db.backends.postgresql",
            "NAME": os.getenv("DB_NAME"),
            "USER": os.getenv("DB_USER"),
            "PASSWORD": os.getenv("DB_PASS"),
            "HOST": _resolved_db_host(),
            "PORT": os.getenv("DB_PORT"),
            # Connection pooling - keep connections alive for 600 seconds
            "CONN_MAX_AGE": 600,
            # Connection pool size per worker
            "CONN_HEALTH_CHECKS": True,
        }
    }


# Password validation
# https://docs.djangoproject.com/en/4.2/ref/settings/#auth-password-validators

AUTH_PASSWORD_VALIDATORS = [
    {
        "NAME": "django.contrib.auth.password_validation.UserAttributeSimilarityValidator",
    },
    {
        "NAME": "django.contrib.auth.password_validation.MinimumLengthValidator",
    },
    {
        "NAME": "django.contrib.auth.password_validation.CommonPasswordValidator",
    },
    {
        "NAME": "django.contrib.auth.password_validation.NumericPasswordValidator",
    },
]


# Internationalization
# https://docs.djangoproject.com/en/4.2/topics/i18n/

LANGUAGE_CODE = "en-us"

TIME_ZONE = "Asia/Singapore"

USE_I18N = True

USE_TZ = True

# Google API settings (service account file path, scopes, timezone)
_google_file = os.getenv("GOOGLE_SERVICE_ACCOUNT_FILE", "crm-revisbali-94d3dc9b6077.json").strip('"').strip("'")
if not os.path.isabs(_google_file):
    GOOGLE_SERVICE_ACCOUNT_FILE = os.path.join(ROOT_DIR, _google_file)
else:
    GOOGLE_SERVICE_ACCOUNT_FILE = _google_file

GOOGLE_SCOPES = _parse_list(
    os.getenv(
        "GOOGLE_SCOPES",
        "https://www.googleapis.com/auth/calendar,https://www.googleapis.com/auth/tasks",
    )
)
GOOGLE_TIMEZONE = os.getenv("GOOGLE_TIMEZONE", "Asia/Makassar")
GOOGLE_CALENDAR_ID = os.getenv("GOOGLE_CALENDAR_ID", "primary")
GOOGLE_TASKLIST_ID = os.getenv("GOOGLE_TASKLIST_ID", "@default")
GOOGLE_CALENDAR_TODO_COLOR_ID = os.getenv("GOOGLE_CALENDAR_TODO_COLOR_ID", "5")
GOOGLE_CALENDAR_DONE_COLOR_ID = os.getenv("GOOGLE_CALENDAR_DONE_COLOR_ID", "10")

# Configure project locale path for translations (locale is at project root, one level up from BASE_DIR)
LOCALE_PATHS = [os.path.join(BASE_DIR, "..", "locale")]

# Audit configuration: Audits are persisted by `django-auditlog` (DB `LogEntry` objects). Local
# Audit settings (using django-auditlog)
# Runtime toggles controlled by environment variables. Defaults to True when not set.
# Global audit enable/disable at startup. When False, django-auditlog app and middleware are omitted.
AUDIT_ENABLED = _parse_bool(os.getenv("AUDIT_ENABLED", "True"))
# Per-event watch flags (control which events are recorded/forwarded)
AUDIT_WATCH_CRUD_EVENTS = _parse_bool(
    os.getenv("AUDIT_WATCH_CRUD_EVENTS", os.getenv("AUDIT_WATCH_MODEL_EVENTS", "True"))
)
AUDIT_WATCH_AUTH_EVENTS = _parse_bool(os.getenv("AUDIT_WATCH_AUTH_EVENTS", "True"))
AUDIT_WATCH_REQUEST_EVENTS = _parse_bool(os.getenv("AUDIT_WATCH_REQUEST_EVENTS", "True"))
# Avoid logging request events for static/media files when forwarding structured logs. Support comma-separated env var.
AUDIT_URL_SKIP_LIST = _parse_list(os.getenv("AUDIT_URL_SKIP_LIST"), ["/static/", "/media/", "/favicon.ico"])
# Purge retention for forwarded audit logs (not the DB retention of LogEntry)
AUDIT_PURGE_AFTER_DAYS = int(os.getenv("AUDIT_PURGE_AFTER_DAYS", "90"))


# Static files (CSS, JavaScript, Images)
# https://docs.djangoproject.com/en/4.2/howto/static-files/

STATIC_URL = "static/"

# Default primary key field type
# https://docs.djangoproject.com/en/4.2/ref/settings/#default-auto-field

DEFAULT_AUTO_FIELD = "django.db.models.BigAutoField"

#
# STEF
#


# by default, all views require login. To allow anonymous access, add the view name to UNAUTHENTICATED_URLS
LOGIN_URL = "/login/"
LOGOUT_URL = "/logout/"
LOGIN_EXEMPT_URLS = (
    r"^login/$",
    r"^logout/$",
    r"^api/.*$",  # match 'api/' and any subpaths
    r"^api-token-auth/$",
    # Media/static assets are requested by the browser without Bearer headers.
    # Keep these paths public so file/image URLs in the SPA can render.
    r"^uploads/.*$",
    r"^media/.*$",
    r"^static/.*$",
    r"^staticfiles/.*$",
)

LOGOUT_REDIRECT_URL = "/login"

STATICFILES_DIRS = [
    os.path.join(BASE_DIR, "static"),
]

CSRF_COOKIE_SECURE = True
SESSION_COOKIE_SECURE = True
CSRF_COOKIE_DOMAIN = APP_DOMAIN
SESSION_COOKIE_DOMAIN = APP_DOMAIN
CSRF_TRUSTED_ORIGINS = [
    f"https://www.admin.{APP_DOMAIN}",
    f"https://admin.{APP_DOMAIN}",
    f"https://www.{APP_DOMAIN}",
    f"https://{APP_DOMAIN}",
    "https://localhost",
    "http://localhost",
    "http://localhost:4200",
]
SESSION_COOKIE_SAMESITE = "Lax"  # Changed from "None" - use Lax for same-site Django apps
CSRF_COOKIE_SAMESITE = "Lax"  # Changed from "None"

# Read log level from DJANGO_LOG_LEVEL or fall back to generic LOG_LEVEL; default to INFO.
# Logging level configuration
# DJANGO_LOG_LEVEL = os.getenv("DJANGO_LOG_LEVEL", os.getenv("LOG_LEVEL", "INFO"))

REST_FRAMEWORK = {
    "DEFAULT_AUTHENTICATION_CLASSES": [
        "business_suite.authentication.JwtOrMockAuthentication",
        "rest_framework.authentication.SessionAuthentication",
    ],
    "DEFAULT_PERMISSION_CLASSES": [
        # 'rest_framework.permissions.IsAuthenticated', #the one below is more granular
        "rest_framework.permissions.DjangoModelPermissions",
    ],
    "DEFAULT_RENDERER_CLASSES": [
        "djangorestframework_camel_case.render.CamelCaseJSONRenderer",
        "djangorestframework_camel_case.render.CamelCaseBrowsableAPIRenderer",
        "rest_framework.renderers.JSONRenderer",
        "rest_framework.renderers.BrowsableAPIRenderer",
    ],
    "DEFAULT_PARSER_CLASSES": [
        "djangorestframework_camel_case.parser.CamelCaseJSONParser",
        "djangorestframework_camel_case.parser.CamelCaseFormParser",
        "djangorestframework_camel_case.parser.CamelCaseMultiPartParser",
        "rest_framework.parsers.JSONParser",
        "rest_framework.parsers.FormParser",
        "rest_framework.parsers.MultiPartParser",
        "rest_framework.parsers.FileUploadParser",
    ],
    "DEFAULT_SCHEMA_CLASS": "drf_spectacular.openapi.AutoSchema",
    "EXCEPTION_HANDLER": "api.utils.exception_handler.custom_exception_handler",
    # Ensure FileField/ImageField serializers expose URL values (not plain storage keys).
    "UPLOADED_FILES_USE_URL": True,
    "DEFAULT_THROTTLE_CLASSES": [
        "rest_framework.throttling.AnonRateThrottle",
        "rest_framework.throttling.UserRateThrottle",
        "rest_framework.throttling.ScopedRateThrottle",
    ],
    "DEFAULT_THROTTLE_RATES": {
        "anon": "100/day",
        "user": "1000/day",
        "quick_create": "20/minute",
        "cron": "5/minute",
        "ocr": "10/minute",
        "ocr_status": "120/minute",
        "document_ocr": "10/minute",
        "document_ocr_status": "120/minute",
        "products_export_start": "6/minute",
        "products_import_start": "6/minute",
        "invoice_download_async": "10/minute",
        "invoice_import_batch": "4/minute",
    },
}

SPECTACULAR_SETTINGS = {
    "TITLE": "BusinessSuite API",
    "DESCRIPTION": "API for BusinessSuite ERP/CRM",
    "VERSION": "1.0.0",
    "SERVE_INCLUDE_SCHEMA": False,
    "CAMELIZE_NAMES": True,
    "COMPONENT_SPLIT_PATCH": False,
    # Preprocessing hooks help filter out endpoints that are hard to auto-discover
    # We add a hook that excludes APIView endpoints without serializer declarations
    "PREPROCESSING_HOOKS": ["core.openapi.preprocess_exclude_api_views_without_serializer"],
    "POSTPROCESSING_HOOKS": [
        "core.openapi.postprocess_add_job_id_param",
        "core.openapi.postprocess_fix_empty_204_responses",
        "core.openapi.postprocess_add_mock_paths",
    ],
    # ENUM_NAME_OVERRIDES maps a friendly enum name to a choices definition (import path or callable)
    # This avoids drf-spectacular generating many colliding enum names for fields named 'status'.
    "ENUM_NAME_OVERRIDES": {
        # DocApplication and DocWorkflow share the same choices; use a single override name
        "DocApplicationStatus": "customer_applications.models.doc_application.DocApplication.STATUS_CHOICES",
        "InvoiceStatus": "invoices.models.invoice.Invoice.INVOICE_STATUS_CHOICES",
        "InvoicePaymentStatus": "invoices.models.invoice.InvoiceApplication.PAYMENT_STATUS_CHOICES",
        # Consolidate identical job status choices under a single shared enum name to avoid duplication
        "JobStatus": ["queued", "processing", "completed", "failed"],
    },
}

SIMPLE_JWT = {
    "ACCESS_TOKEN_LIFETIME": timedelta(days=1),
    "REFRESH_TOKEN_LIFETIME": timedelta(days=7),
    "ROTATE_REFRESH_TOKENS": False,
    "BLACKLIST_AFTER_ROTATION": False,
    "UPDATE_LAST_LOGIN": True,
    "ALGORITHM": "HS256",
    "SIGNING_KEY": SECRET_KEY,
    "VERIFYING_KEY": None,
    "AUDIENCE": None,
    "ISSUER": None,
    "JWK_URL": None,
    "LEEWAY": 0,
    "AUTH_HEADER_TYPES": ("Bearer",),
    "AUTH_HEADER_NAME": "HTTP_AUTHORIZATION",
    "USER_ID_FIELD": "id",
    "USER_ID_CLAIM": "user_id",
    "USER_AUTHENTICATION_RULE": "rest_framework_simplejwt.authentication.default_user_authentication_rule",
    "AUTH_TOKEN_CLASSES": ("rest_framework_simplejwt.tokens.AccessToken",),
    "TOKEN_TYPE_CLAIM": "token_type",
    "TOKEN_USER_CLASS": "rest_framework_simplejwt.models.TokenUser",
    "JTI_CLAIM": "jti",
}

# CORS configuration - read from environment in production
# Preferred env var: CORS_ALLOWED_ORIGINS (comma separated list of origins)
# Fallback defaults include localhost dev ports and the configured APP_DOMAIN
_default_cors_origins = [
    "http://localhost:3000",
    "http://localhost:4200",
]
if APP_DOMAIN:
    _default_cors_origins += [f"https://{APP_DOMAIN}", f"https://admin.{APP_DOMAIN}", f"https://www.{APP_DOMAIN}"]

CORS_ALLOWED_ORIGINS = _parse_list(os.getenv("CORS_ALLOWED_ORIGINS", ",".join(_default_cors_origins)))
# Allow credentials (cookies) only when explicitly enabled in env var (default False for safety)
CORS_ALLOW_CREDENTIALS = _parse_bool(os.getenv("CORS_ALLOW_CREDENTIALS", "False"))
# Ensure common headers (including Authorization) are allowed for preflight requests.
# Use defaults from django-cors-headers and extend if needed.
try:
    from corsheaders.defaults import default_headers
except Exception:  # pragma: no cover - optional package
    CORS_ALLOW_HEADERS = None
else:
    CORS_ALLOW_HEADERS = list(default_headers) + ["authorization"]

CORS_ALLOW_METHODS = ["GET", "POST", "PUT", "PATCH", "DELETE", "OPTIONS"]
# Expose Content-Disposition so the frontend can read filename from responses
try:
    from corsheaders.defaults import default_headers as _default_cors_headers
except Exception:  # pragma: no cover - optional package
    CORS_EXPOSE_HEADERS = ["Content-Disposition"]
else:
    # combine and ensure uniqueness
    CORS_EXPOSE_HEADERS = list(
        {*(getattr(globals().get("CORS_EXPOSE_HEADERS", []), "copy", lambda: [])()), *["Content-Disposition"]}
    )

# https://github.com/legion-an/django-models-logging
LOGGING_MODELS = (
    # 'app.ClassName',      # logging only for this model
    "customers",  # logging of all models in this app
    "products",
    "invoices",
    "customer_applications",
)

SESSION_SAVE_EVERY_REQUEST = True

# This is for the debug toolbar when using docker
# https://docs.djangoproject.com/en/3.2/ref/settings/#internal-ips
# if DEBUG:
#     import socket  # only if you haven't already imported this
#     hostname, _, ips = socket.gethostbyname_ex(socket.gethostname())
#     INTERNAL_IPS = [ip[: ip.rfind(".")] + ".1" for ip in ips] + ["127.0.0.1", "10.0.2.2"]


CACHES = build_prod_redis_caches()

# Cacheops Configuration - uses Redis database 2 (Huey uses default DB 0, Django cache uses DB 1)
# Parse REDIS_URL and replace the database number with 2 for cacheops
_redis_url = os.getenv("REDIS_URL", "redis://redis:6379/1")
# Replace the database number in the URL (e.g., /1 -> /2)
if _redis_url.rfind("/") > _redis_url.rfind(":"):
    # URL has a database number, replace it
    CACHEOPS_REDIS = _redis_url.rsplit("/", 1)[0] + "/2"
else:
    # URL doesn't have a database number, append /2
    CACHEOPS_REDIS = _redis_url.rstrip("/") + "/2"

# Per-model cache configuration
# Optimized based on benchmark results (Task 21.3)
# Strategy: Static/reference data (1-24 hours), User data (10-15 minutes),
# Content data (2-5 minutes), Real-time data (30 seconds - 1 minute)
# See backend/cache/OPTIMIZATION_NOTES.md for detailed rationale
CACHEOPS = {
    # Static/reference data - rarely changes (1-24 hours)
    # Rationale: Maximizes cache hit rate for frequently accessed reference data
    "auth.permission": {"ops": "all", "timeout": 60 * 60},  # 1 hour
    "contenttypes.*": {"ops": "all", "timeout": 60 * 60 * 24},  # 24 hours
    "core.countrycode": {"ops": "all", "timeout": 60 * 60 * 24},  # 24 hours
    "core.holiday": {"ops": "all", "timeout": 60 * 60 * 24},  # 24 hours
    "products.documenttype": {"ops": "all", "timeout": 60 * 60},  # 1 hour
    "products.product": {"ops": "all", "timeout": 60 * 60},  # 1 hour
    "products.task": {"ops": "all", "timeout": 60 * 60},  # 1 hour
    # User data - moderate change frequency (10-15 minutes)
    # Rationale: Reduces database load for user authentication and profile lookups
    "auth.user": {"ops": "get", "timeout": 60 * 15},  # 15 minutes
    "core.userprofile": {"ops": "get", "timeout": 60 * 15},  # 15 minutes
    "core.usersettings": {"ops": "get", "timeout": 60 * 15},  # 15 minutes
    "customers.customer": {"ops": "all", "timeout": 60 * 10},  # 10 minutes
    # Content data - frequent changes (2-5 minutes)
    # Rationale: Balances freshness with cache efficiency for business data
    "invoices.invoice": {"ops": "all", "timeout": 60 * 5},  # 5 minutes
    "invoices.invoiceapplication": {"ops": "all", "timeout": 60 * 5},  # 5 minutes
    "payments.payment": {"ops": "all", "timeout": 60 * 5},  # 5 minutes
    "customer_applications.docapplication": {"ops": "all", "timeout": 60 * 5},  # 5 minutes
    "customer_applications.document": {"ops": "all", "timeout": 60 * 5},  # 5 minutes
    "customer_applications.docworkflow": {"ops": "all", "timeout": 60 * 2},  # 2 minutes
    "core.calendarevent": {"ops": "all", "timeout": 60 * 2},  # 2 minutes
    # Real-time/notification data - very frequent changes (30 seconds)
    # Rationale: Provides caching benefit while maintaining near-real-time freshness
    "core.calendarreminder": {"ops": "get", "timeout": 30},  # 30 seconds
    "customer_applications.workflownotification": {"ops": "get", "timeout": 30},  # 30 seconds
    "core.webpushsubscription": {"ops": "get", "timeout": 30},  # 30 seconds
    # Job/task tracking - short-lived (1 minute)
    # Rationale: Job status needs frequent updates but benefits from brief caching
    "core.ocrjob": {"ops": "get", "timeout": 60},  # 1 minute
    "core.documentocrjob": {"ops": "get", "timeout": 60},  # 1 minute
    "core.asyncjob": {"ops": "get", "timeout": 60},  # 1 minute
    "invoices.invoiceimportjob": {"ops": "get", "timeout": 60},  # 1 minute
    "invoices.invoiceimportitem": {"ops": "get", "timeout": 60},  # 1 minute
    "invoices.invoicedownloadjob": {"ops": "get", "timeout": 60},  # 1 minute
    "invoices.invoicedocumentjob": {"ops": "get", "timeout": 60},  # 1 minute
    "invoices.invoicedocumentitem": {"ops": "get", "timeout": 60},  # 1 minute
}

# Graceful fallback to database on cache errors
CACHEOPS_DEGRADE_ON_FAILURE = True

# Content Security Policy support: generate per-request nonces and expose mode
CSP_ENABLED = _parse_bool(os.getenv("CSP_ENABLED", "False"))
CSP_MODE = os.getenv("CSP_MODE", "report-only")  # report-only|enforce

_HUEY_WORKERS = int(os.getenv("HUEY_WORKERS", "2"))
_HUEY_INITIAL_DELAY = float(os.getenv("HUEY_INITIAL_DELAY", "0.05"))
_HUEY_BACKOFF = float(os.getenv("HUEY_BACKOFF", "1.05"))
_HUEY_MAX_DELAY = float(os.getenv("HUEY_MAX_DELAY", "1.0"))


def _build_huey_settings(testing: bool) -> dict:
    if testing:
        from peewee import SqliteDatabase

        huey_database = SqliteDatabase(":memory:")
        return {
            "huey_class": "huey.contrib.sql_huey.SqlHuey",
            "name": "business_suite",
            "results": True,
            "immediate": False,
            "database": huey_database,
            "consumer": {
                "workers": _HUEY_WORKERS,
                "worker_type": os.getenv("HUEY_WORKER_TYPE", "thread"),
                # SqlHuey is polling-based; tighter bounds reduce idle pickup latency.
                "initial_delay": _HUEY_INITIAL_DELAY,
                "backoff": _HUEY_BACKOFF,
                "max_delay": _HUEY_MAX_DELAY,
                "scheduler_interval": 1,
                "check_worker_health": True,
                "health_check_interval": 1,
            },
        }

    # Prefer the explicit contrib path when available, but support newer Huey
    # versions that expose RedisHuey at package root.
    redis_huey_class = "huey.contrib.redis_huey.RedisHuey"
    try:
        import_module("huey.contrib.redis_huey")
    except ModuleNotFoundError:
        redis_huey_class = "huey.RedisHuey"

    # production / non-testing Huey -> Redis
    return {
        "huey_class": redis_huey_class,
        "name": "business_suite",
        "immediate": False,
        "connection": {
            "host": _resolved_redis_host(),
            "port": int(os.getenv("REDIS_PORT", "6379")),
            "db": int(os.getenv("HUEY_REDIS_DB", "0")),
        },
        "consumer": {
            "workers": _HUEY_WORKERS,
            "worker_type": os.getenv("HUEY_WORKER_TYPE", "thread"),
            "initial_delay": _HUEY_INITIAL_DELAY,
            "backoff": _HUEY_BACKOFF,
            "max_delay": _HUEY_MAX_DELAY,
            "scheduler_interval": 1,
            "check_worker_health": True,
            "health_check_interval": 1,
        },
    }


HUEY = _build_huey_settings(TESTING)

# select2
SELECT2_CACHE_BACKEND = "select2"

# SESSION_ENGINE = "django.contrib.sessions.backends.cache"
# # SESSION_COOKIE_AGE = 60 * 60 * 24  # One day
# SESSION_COOKIE_AGE = 60 * 5 # 5 minutes

TESSERACT_CMD = "/opt/homebrew/bin/tesseract"


# Settings for Django static and media files
STATICFILES_STORAGE = "whitenoise.storage.CompressedManifestStaticFilesStorage"


# Storage configuration
USE_CLOUD_STORAGE = _parse_bool(os.getenv("USE_CLOUD_STORAGE", "False"))
LOCAL_MEDIA_ENCRYPTION_ENABLED = _parse_bool(os.getenv("LOCAL_MEDIA_ENCRYPTION_ENABLED", "False"))
LOCAL_MEDIA_ENCRYPTION_KEY = os.getenv("LOCAL_MEDIA_ENCRYPTION_KEY", "")
OCR_PREVIEW_STORAGE_PREFIX = os.getenv("OCR_PREVIEW_STORAGE_PREFIX", "ocr_previews")
_settings_module = os.getenv("DJANGO_SETTINGS_MODULE", "")
_default_bucket_name = "crmrevisbali" if _settings_module.endswith(".prod") else "crmrevisbalidev"

AWS_ACCESS_KEY_ID = os.getenv("AWS_ACCESS_KEY_ID")
AWS_SECRET_ACCESS_KEY = os.getenv("AWS_SECRET_ACCESS_KEY")
AWS_STORAGE_BUCKET_NAME = os.getenv("AWS_STORAGE_BUCKET_NAME", _default_bucket_name)
AWS_S3_ENDPOINT_URL = os.getenv("AWS_S3_ENDPOINT_URL")
AWS_S3_REGION_NAME = os.getenv("AWS_S3_REGION_NAME", "auto")
AWS_S3_SIGNATURE_VERSION = os.getenv("AWS_S3_SIGNATURE_VERSION", "s3v4")
AWS_S3_ADDRESSING_STYLE = os.getenv("AWS_S3_ADDRESSING_STYLE", "virtual")
AWS_S3_CUSTOM_DOMAIN = os.getenv("AWS_S3_CUSTOM_DOMAIN")
AWS_QUERYSTRING_AUTH = _parse_bool(os.getenv("AWS_QUERYSTRING_AUTH", "True"))
AWS_QUERYSTRING_EXPIRE = int(os.getenv("AWS_QUERYSTRING_EXPIRE", "3600"))
AWS_DEFAULT_ACL = None
AWS_DBBACKUP_LOCATION = os.getenv("AWS_DBBACKUP_LOCATION", "backups")

if USE_CLOUD_STORAGE:
    DEFAULT_FILE_STORAGE = "storages.backends.s3boto3.S3Boto3Storage"
elif LOCAL_MEDIA_ENCRYPTION_ENABLED:
    DEFAULT_FILE_STORAGE = "core.storage.encrypted_local.EncryptedLocalStorage"
else:
    DEFAULT_FILE_STORAGE = "django.core.files.storage.FileSystemStorage"

STORAGES = {
    "default": {
        "BACKEND": DEFAULT_FILE_STORAGE,
    },
    "staticfiles": {
        "BACKEND": "whitenoise.storage.CompressedManifestStaticFilesStorage",
    },
    "dbbackup": {
        "BACKEND": "storages.backends.s3boto3.S3Boto3Storage",
        "OPTIONS": {
            "location": AWS_DBBACKUP_LOCATION,
        },
    },
}
DBBACKUP_STORAGE = "storages.backends.s3boto3.S3Boto3Storage"
DBBACKUP_STORAGE_OPTIONS = {"location": AWS_DBBACKUP_LOCATION}

# Folders to exclude from media backup
DBBACKUP_EXCLUDE_MEDIA_FODERS = ["tmpfiles"]
# Force dbbackup to use a compatible PostgreSQL client wrapper by default.
# This avoids pg_dump major-version mismatches on developer machines where the
# database server (e.g., in Docker) is newer than the local Homebrew client.
DBBACKUP_DUMP_CMD = os.getenv("DBBACKUP_DUMP_CMD", str(ROOT_DIR / "scripts" / "pg_dump_compat.sh"))
DBBACKUP_RESTORE_CMD = os.getenv(
    "DBBACKUP_RESTORE_CMD",
    str(ROOT_DIR / "scripts" / "pg_restore_compat.sh"),
)
DBBACKUP_CONNECTORS = {
    database_alias: {
        "DUMP_CMD": DBBACKUP_DUMP_CMD,
        "RESTORE_CMD": DBBACKUP_RESTORE_CMD,
    }
    for database_alias, database_config in DATABASES.items()
    if "postgresql" in database_config.get("ENGINE", "")
}

FULL_BACKUP_SCHEDULE = "02:00"
CLEAR_CACHE_SCHEDULE = ["03:00"]

# Database retention for audit log DB `LogEntry` objects.
# Default to 14 days; set to 0 or negative to disable automatic pruning.
AUDITLOG_RETENTION_DAYS = int(os.getenv("AUDITLOG_RETENTION_DAYS", "14"))
# Daily schedule for audit log pruning (HH:MM 24h). Set to empty string to disable scheduling.
AUDITLOG_RETENTION_SCHEDULE = os.getenv("AUDITLOG_RETENTION_SCHEDULE", "04:00")

# Daily customer reminder notification schedule (GMT+8 project timezone).
CUSTOMER_NOTIFICATIONS_DAILY_HOUR = int(os.getenv("CUSTOMER_NOTIFICATIONS_DAILY_HOUR", "8"))
CUSTOMER_NOTIFICATIONS_DAILY_MINUTE = int(os.getenv("CUSTOMER_NOTIFICATIONS_DAILY_MINUTE", "0"))

# Calendar reminder push dispatch settings.
# Huey periodic task checks reminders every minute and processes at most this many rows per run.
CALENDAR_REMINDER_DISPATCH_LIMIT = int(os.getenv("CALENDAR_REMINDER_DISPATCH_LIMIT", "200"))

# Local-first synchronization settings (desktop replica mode).
LOCAL_SYNC_ENABLED = _parse_bool(os.getenv("LOCAL_SYNC_ENABLED", "False"))
LOCAL_SYNC_NODE_ID = os.getenv("LOCAL_SYNC_NODE_ID", socket.gethostname())
LOCAL_SYNC_REMOTE_BASE_URL = os.getenv("LOCAL_SYNC_REMOTE_BASE_URL", "").strip().rstrip("/")
LOCAL_SYNC_REMOTE_TOKEN = os.getenv("LOCAL_SYNC_REMOTE_TOKEN", "").strip()
LOCAL_SYNC_PUSH_LIMIT = int(os.getenv("LOCAL_SYNC_PUSH_LIMIT", "200"))
LOCAL_SYNC_PULL_LIMIT = int(os.getenv("LOCAL_SYNC_PULL_LIMIT", "200"))
LOCAL_SYNC_REQUEST_TIMEOUT_SECONDS = float(os.getenv("LOCAL_SYNC_REQUEST_TIMEOUT_SECONDS", "10"))

# Conditionally enable the `auditlog` app and its middleware (so the feature can be fully toggled at startup)
if AUDIT_ENABLED:
    # Add auditlog to installed apps if missing
    if "auditlog" not in INSTALLED_APPS:
        INSTALLED_APPS.append("auditlog")

    # Insert middleware after our performance logger if present, otherwise append at the end
    try:
        idx = MIDDLEWARE.index("core.middleware.performance_logger.PerformanceLoggingMiddleware")
        MIDDLEWARE.insert(idx + 1, "auditlog.middleware.AuditlogMiddleware")
    except ValueError:
        if "auditlog.middleware.AuditlogMiddleware" not in MIDDLEWARE:
            MIDDLEWARE.append("auditlog.middleware.AuditlogMiddleware")
else:
    # Explicitly avoid leaving audit middleware or app configured
    if "auditlog" in INSTALLED_APPS:
        INSTALLED_APPS.remove("auditlog")
    if "auditlog.middleware.AuditlogMiddleware" in MIDDLEWARE:
        MIDDLEWARE.remove("auditlog.middleware.AuditlogMiddleware")

# Determine if we are running as backend or task_worker
# Default to 'backend' unless 'run_huey' is in command line or COMPONENT is set.
COMPONENT = os.getenv("COMPONENT")
if not COMPONENT:
    if "run_huey" in sys.argv:
        COMPONENT = "task_worker"
    else:
        COMPONENT = "backend"

# Define the primary handler for this component
PRIMARY_HANDLER = "backend_file" if COMPONENT == "backend" else "task_worker_file"

LOGGING = {
    "version": 1,
    "disable_existing_loggers": False,
    "formatters": {
        "verbose": {
            "format": "{levelname} {asctime} {module} {process} {thread} {message}",
            "style": "{",
        },
        "simple": {
            "format": "{levelname} {message}",
            "style": "{",
        },
    },
    "filters": {
        "require_debug_true": {
            "()": "django.utils.log.RequireDebugTrue",
        },
    },
    "handlers": {
        "console": {
            "class": "logging.StreamHandler",
            "formatter": "simple",
        },
        "backend_file": {
            "level": "INFO",
            "class": "concurrent_log_handler.ConcurrentRotatingFileHandler",
            "filename": os.path.join(LOG_DIR, "django.log"),
            "maxBytes": 10 * 1024 * 1024,
            "backupCount": 10,
            "formatter": "verbose",
        },
        "task_worker_file": {
            "level": "INFO",
            "class": "concurrent_log_handler.ConcurrentRotatingFileHandler",
            "filename": os.path.join(LOG_DIR, "task_worker.log"),
            "maxBytes": 10 * 1024 * 1024,
            "backupCount": 10,
            "formatter": "verbose",
        },
    },
    "root": {
        "handlers": ["console", PRIMARY_HANDLER],
        "level": "WARNING",
    },
    "loggers": {
        "django": {
            "handlers": ["console", PRIMARY_HANDLER],
            "level": DJANGO_LOG_LEVEL,
            "propagate": False,
        },
        "django.request": {
            "handlers": ["console", PRIMARY_HANDLER],
            "level": "ERROR",
            "propagate": False,
        },
        "huey": {
            "handlers": ["console", PRIMARY_HANDLER],
            "level": "INFO",
            "propagate": False,
        },
        "performance": {
            "handlers": ["console", PRIMARY_HANDLER],
            "level": "INFO",
            "propagate": False,
        },
        "core": {
            "handlers": ["console", PRIMARY_HANDLER],
            "level": "INFO",
            "propagate": False,
        },
        "core.tasks.calendar_sync": {
            "handlers": ["console", PRIMARY_HANDLER],
            "level": "DEBUG",
            "propagate": False,
        },
        "core.signals_calendar": {
            "handlers": ["console", PRIMARY_HANDLER],
            "level": "DEBUG",
            "propagate": False,
        },
        "customer_applications.services.application_calendar_service": {
            "handlers": ["console", PRIMARY_HANDLER],
            "level": "DEBUG",
            "propagate": False,
        },
    },
}

# Remove the manual loop and use the standard Django logging configuration.
# The Logger service can still be used for ad-hoc loggers.

# Note: Loki-specific attachment of handlers has been removed. Grafana Alloy should
# scrape container stdout/stderr or log files (e.g., `logs/`) to collect logs. If you
# want additional loggers to forward audit events to the file-based fallback handler,
# add "fail_safe_audit" to their handler lists here.
CURRENCY = "IDR"
CURRENCY_SYMBOL = "Rp"
CURRENCY_DECIMAL_PLACES = 0

# OpenAI API configuration for invoice import
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

OPENROUTER_API_KEY = os.getenv("OPENROUTER_API_KEY")
OPENROUTER_API_BASE_URL = os.getenv("OPENROUTER_API_BASE_URL", "https://openrouter.ai/api/v1")
OPENROUTER_HEALTHCHECK_ENABLED = _parse_bool(
    os.getenv("OPENROUTER_HEALTHCHECK_ENABLED", "True" if OPENROUTER_API_KEY else "False")
)
OPENROUTER_HEALTHCHECK_TIMEOUT = float(os.getenv("OPENROUTER_HEALTHCHECK_TIMEOUT", "10"))
OPENROUTER_HEALTHCHECK_CRON_MINUTE = os.getenv("OPENROUTER_HEALTHCHECK_CRON_MINUTE", "*/5")
OPENROUTER_HEALTHCHECK_MIN_CREDIT_REMAINING = float(os.getenv("OPENROUTER_HEALTHCHECK_MIN_CREDIT_REMAINING", "0"))

# LLM Provider: "openrouter" for multi-provider access, "openai" for direct OpenAI API
LLM_PROVIDER = os.getenv("LLM_PROVIDER", "openrouter")
LLM_DEFAULT_MODEL = os.getenv("LLM_DEFAULT_MODEL", "google/gemini-2.5-flash-lite")
# Dedicated model for document categorization; falls back to global LLM default when unset.
DOCUMENT_CATEGORIZER_MODEL = os.getenv("DOCUMENT_CATEGORIZER_MODEL", LLM_DEFAULT_MODEL)
# Higher-tier model used as fallback when the primary categorizer fails to classify.
DOCUMENT_CATEGORIZER_MODEL_HIGH = os.getenv("DOCUMENT_CATEGORIZER_MODEL_HIGH", "google/gemini-3-flash-preview")
# Dedicated model for document validation (positive/negative prompt analysis).
DOCUMENT_VALIDATOR_MODEL = os.getenv("DOCUMENT_VALIDATOR_MODEL", "google/gemini-3-flash-preview")

NOTIFICATION_FROM_EMAIL = os.getenv("NOTIFICATION_FROM_EMAIL", "dewi@revisbali.com")
GMAIL_APP_PASSWORD = os.getenv("GMAIL_APP_PASSWORD")

EMAIL_BACKEND = "django.core.mail.backends.smtp.EmailBackend"
EMAIL_HOST = os.getenv("EMAIL_HOST", "smtp.gmail.com")
EMAIL_PORT = int(os.getenv("EMAIL_PORT", "587"))
EMAIL_HOST_USER = NOTIFICATION_FROM_EMAIL
EMAIL_HOST_PASSWORD = GMAIL_APP_PASSWORD
EMAIL_USE_TLS = os.getenv("EMAIL_USE_TLS", "true").lower() == "true"
DEFAULT_FROM_EMAIL = NOTIFICATION_FROM_EMAIL

# Whatsapp (meta) business API configuration
META_APP_ID = os.getenv("META_APP_ID", "")
META_APP_SECRET = os.getenv("META_APP_SECRET", "")
META_PHONE_NUMBER_ID = os.getenv("META_PHONE_NUMBER_ID", "")
META_WHATSAPP_BUSINESS_NUMBER_ID = os.getenv("META_WHATSAPP_BUSINESS_NUMBER_ID", "")
META_WHATSAPP_BUSINESS_NUMBER = os.getenv("META_WHATSAPP_BUSINESS_NUMBER", "")
META_WHATSAPP_ACCESS_TOKEN = os.getenv("META_WHATSAPP_ACCESS_TOKEN", "")
META_TOKEN_CLIENT = os.getenv("META_TOKEN_CLIENT", "")
META_GRAPH_API_VERSION = os.getenv("META_GRAPH_API_VERSION", "v23.0")
META_WHATSAPP_AUTO_REFRESH_ACCESS_TOKEN = _parse_bool(os.getenv("META_WHATSAPP_AUTO_REFRESH_ACCESS_TOKEN", "True"))
META_WHATSAPP_TOKEN_REFRESH_WINDOW_SECONDS = int(
    os.getenv("META_WHATSAPP_TOKEN_REFRESH_WINDOW_SECONDS", str(7 * 24 * 60 * 60))
)
META_WHATSAPP_TOKEN_CACHE_TIMEOUT_SECONDS = int(
    os.getenv("META_WHATSAPP_TOKEN_CACHE_TIMEOUT_SECONDS", str(70 * 24 * 60 * 60))
)
META_WEBHOOK_ENFORCE_SIGNATURE = (
    os.getenv("META_WEBHOOK_ENFORCE_SIGNATURE", "false" if DEBUG else "true").lower() == "true"
)
WHATSAPP_TEST_NUMBER = os.getenv("WHATSAPP_TEST_NUMBER", "")

#
# Web Push Notifications (Firebase Cloud Messaging) settings

FCM_SENDER_ID = os.getenv("FCM_SENDER_ID", "").strip()
FCM_VAPID_PUBLIC_KEY = os.getenv("FCM_VAPID_PUBLIC_KEY", "").strip()
FCM_VAPID_PRIVATE_KEY = os.getenv("FCM_VAPID_PRIVATE_KEY", "").strip()

# Legacy setting kept for backward compatibility. In modern Firebase docs this is called `messagingSenderId`.
FCM_PROJECT_NUMBER = os.getenv("FCM_PROJECT_NUMBER", "").strip()
FCM_PROJECT_ID = os.getenv("FCM_PROJECT_ID", "").strip()

# Web app config exposed to Angular for Firebase SDK initialization.
FCM_WEB_API_KEY = os.getenv("FCM_WEB_API_KEY", "").strip()
FCM_WEB_APP_ID = os.getenv("FCM_WEB_APP_ID", "").strip()
FCM_WEB_AUTH_DOMAIN = os.getenv("FCM_WEB_AUTH_DOMAIN", "").strip()
FCM_WEB_STORAGE_BUCKET = os.getenv("FCM_WEB_STORAGE_BUCKET", "").strip()
FCM_WEB_MEASUREMENT_ID = os.getenv("FCM_WEB_MEASUREMENT_ID", "").strip()

_fcm_file = os.getenv("GOOGLE_FCM_SERVICE_ACCOUNT_FILE", "").strip().strip('"').strip("'")
if _fcm_file:
    if os.path.isabs(_fcm_file):
        GOOGLE_FCM_SERVICE_ACCOUNT_FILE = _fcm_file
    else:
        GOOGLE_FCM_SERVICE_ACCOUNT_FILE = os.path.join(ROOT_DIR, _fcm_file)
else:
    GOOGLE_FCM_SERVICE_ACCOUNT_FILE = ""

# FCM HTTP v1 endpoint requires a project id (string). If missing, derive from service account json.
if not FCM_PROJECT_ID and GOOGLE_FCM_SERVICE_ACCOUNT_FILE and os.path.exists(GOOGLE_FCM_SERVICE_ACCOUNT_FILE):
    try:
        with open(GOOGLE_FCM_SERVICE_ACCOUNT_FILE, "r", encoding="utf-8") as f:
            _fcm_sa_payload = json.load(f)
        FCM_PROJECT_ID = str(_fcm_sa_payload.get("project_id") or "").strip()
    except Exception:
        FCM_PROJECT_ID = ""
